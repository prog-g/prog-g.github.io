---
layout: post
tag: [ 岐大祭2018 ]
---

この記事は、岐大祭に向けてアドベントカレンダー的な記事を書く企画の最終日(7日目)です。

今回は自然言語処理の「前処理」の話をしていきたいと思います。
若干ですが、コードも載せておきます。使用する言語はPythonです。

## 自然言語処理とは
私たちが普段使っているような言葉のことを自然言語と言います。
プログラミング言語のような人工言語と区別するために自然言語と称されています。
要するに自然言語処理とは、日常的に目にする文書や使っている言葉を対象にして何か処理をすることです。

この技術は情報検索や翻訳など様々な場面で使われています。

## 前処理
テキストデータを利用して何か処理を行う際、その前段階の処理が予想以上に重要だと感じています。
前処理をするしないでは、その後の処理に大きな影響を及ぼす場合がありました。
今回はその中で、やったことをいくつか取り上げて紹介していきたいと思います。

### 文章を単語ごとに切り分ける
単語は意味をもつ文構成の最小の単位です。
文章の意味を捉えるためには、その文章内の単語の意味を捉えていけばよさそうだというのは何となくイメージがわくかと思います。
そんなわけで単語単位で処理を行いたいという場面が多くあり、まずは単語に切り分けていく必要があります。

英語では下記の例のように単語の切れ目に注目して、単純なものであれば容易に単語ごとに切り分けることができます。
```py
input = "I can speak English well"
print(input.split())
> ['I', 'can', 'speak', 'English', 'well']
```
しかし、日本語は単語の切れ目というのがパッと見分かりません。
そこで、[MeCab](http://taku910.github.io/mecab/)や[JUMAN++](http://nlp.ist.i.kyoto-u.ac.jp/index.php?JUMAN++)などの形態素解析器を利用します。
下記のコードではMeCabを使っています。
```py
input = "私は上手に英語を話すことができます"
import MeCab
mecab = MeCab.Tagger("-Owakati")
me_parse = mecab.parse(input)
words = me_parse.split()
print(words)
> ['私', 'は', '上手', 'に', '英語', 'を', '話す', 'こと', 'が', 'でき', 'ます']
```
しかし、全てが上手くいくわけではなく、時々予想外な切れ方をするときがありました。
MeCabの辞書を追加したりすることである程度対処できるものの難しい問題です。
新語・固有表現に強いという[NEologd](https://github.com/neologd/mecab-ipadic-neologd)を使用するといいかもしれません。

### 半角・全角の対処
テキストデータを扱っていると、たびたび数字やカタカナで半角、全角が混じったものが見られます。
半角と全角はそれぞれ別物と捉えられてしまい厄介です。
```py
print("２" == "2")
> False
```
そこで、数字、アルファベットのみを半角にし、それ以外は全角に統一します。
下記ではそのために[mojimoji](https://github.com/studio-ousia/mojimoji)というライブラリを使用しています。
```py
import mojimoji
text = "赤いバラが２本、青いﾊﾞﾗが3本ある。"
text = mojimoji.zen_to_han(text,kana=False)
text = mojimoji.han_to_zen(text,digit=False,ascii=False)
print(text)
> 赤いバラが2本、青いバラが3本ある。
```

### アルファベットの大文字小文字統一
大文字小文字の違いも別物と判断してしまいます。
下記では大文字に統一しています。これは簡単にできます。
```py
input = "I can speak English well"
input = input.upper()
print(input)
> I CAN SPEAK ENGLISH WELL
```
文の中に日本語がある場合にも以上のコードで問題ないかと思います。

### 特徴のない単語を除外する
処理をする上で役に立ちそうにない語があります。それを事前に抜いておく処理です。
先に不要な語のリスト(ストップワード)を決めておき、それを抜くという方法があります。
もちろんこの方法は有用なのですが、不要語を人手で決める必要があり、手間がかかるという問題点もあります。

別の方法として、単語の出現頻度に注目します。あまりにも出現頻度が高い語は、普遍的に存在するために重要ではないと考え、取り除きます。
また、出現頻度が低い語についても、特徴的な語ではないために取り除きます。

このように単語を除去することによって、実行速度に関してもメリットがあります。

## まとめ・感想
前処理は結構地味な作業だったりします。
しかし、前処理が与える影響が大きい場合もあり、無視するのはよくなさそうです。

今回は何か作品を作ったというよりも、その前段階の部分の話でした。
今後、この話を活かし、何かアプリケーションを作っていけたらなと思っています。

## 最後に
本企画は本日が最終日となります。
少しでも興味がわいた・参考になったと思っていただけたら幸いです。

今日は岐大祭でサークルメンバーの作品の展示を行っています。
ぜひ、見に来てください！
